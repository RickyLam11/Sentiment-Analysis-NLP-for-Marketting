{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dictionary-based Sentiment Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading in the small_corpus .csv file created in the \"creating_dataset\" milestone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"../data/sample_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>01 5, 2001</td>\n",
       "      <td>A1NUEOW1WLQARL</td>\n",
       "      <td>B00004WI4D</td>\n",
       "      <td>Third Shift</td>\n",
       "      <td>You heard right, this game has no SaveGame. It...</td>\n",
       "      <td>Some good ideas, but No Save Game &amp; other prob...</td>\n",
       "      <td>978652800</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>08 23, 2016</td>\n",
       "      <td>A3U4WRQMUFFQDS</td>\n",
       "      <td>B00ZQB28XK</td>\n",
       "      <td>J. S. Harvey</td>\n",
       "      <td>Wonder why no one is returning NMS??  sound pr...</td>\n",
       "      <td>sound pretty bad everyone here and youtube say...</td>\n",
       "      <td>1471910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 21, 2015</td>\n",
       "      <td>A1AGVUZU41WHDH</td>\n",
       "      <td>B00129I75I</td>\n",
       "      <td>Mom J.W.</td>\n",
       "      <td>The cords were for the X-Box 360 instead of th...</td>\n",
       "      <td>Wrong cords</td>\n",
       "      <td>1442793600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>05 19, 2015</td>\n",
       "      <td>A2TCG2HV1VJP6V</td>\n",
       "      <td>B000SFK0SE</td>\n",
       "      <td>Ryan Sil. (Gamer &amp;amp; PC/Android indie dev)</td>\n",
       "      <td>Why am I the first person on Amazon to give th...</td>\n",
       "      <td>Where's the imagination?</td>\n",
       "      <td>1431993600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 1, 2013</td>\n",
       "      <td>A38FTSF7HHCII</td>\n",
       "      <td>B007Z3UUF0</td>\n",
       "      <td>Jack Pacini</td>\n",
       "      <td>I really wanted to like this game. I'm a huge ...</td>\n",
       "      <td>Wow! How could the developers find this game fun?</td>\n",
       "      <td>1356998400</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'Format:': ' Video Game'}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0      1.0     False   01 5, 2001  A1NUEOW1WLQARL  B00004WI4D   \n",
       "1      1.0     False  08 23, 2016  A3U4WRQMUFFQDS  B00ZQB28XK   \n",
       "2      1.0      True  09 21, 2015  A1AGVUZU41WHDH  B00129I75I   \n",
       "3      1.0     False  05 19, 2015  A2TCG2HV1VJP6V  B000SFK0SE   \n",
       "4      1.0      True   01 1, 2013   A38FTSF7HHCII  B007Z3UUF0   \n",
       "\n",
       "                                   reviewerName  \\\n",
       "0                                   Third Shift   \n",
       "1                                  J. S. Harvey   \n",
       "2                                      Mom J.W.   \n",
       "3  Ryan Sil. (Gamer &amp; PC/Android indie dev)   \n",
       "4                                   Jack Pacini   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  You heard right, this game has no SaveGame. It...   \n",
       "1  Wonder why no one is returning NMS??  sound pr...   \n",
       "2  The cords were for the X-Box 360 instead of th...   \n",
       "3  Why am I the first person on Amazon to give th...   \n",
       "4  I really wanted to like this game. I'm a huge ...   \n",
       "\n",
       "                                             summary  unixReviewTime  vote  \\\n",
       "0  Some good ideas, but No Save Game & other prob...       978652800   2.0   \n",
       "1  sound pretty bad everyone here and youtube say...      1471910400   NaN   \n",
       "2                                        Wrong cords      1442793600   NaN   \n",
       "3                           Where's the imagination?      1431993600   NaN   \n",
       "4  Wow! How could the developers find this game fun?      1356998400   5.0   \n",
       "\n",
       "                        style image  \n",
       "0                         NaN   NaN  \n",
       "1                         NaN   NaN  \n",
       "2                         NaN   NaN  \n",
       "3                         NaN   NaN  \n",
       "4  {'Format:': ' Video Game'}   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Tokenizing the sentences and words of the reviews\n",
    "Here, We're going to test different versions of word tokenizer on reviews. We'll then decide which tokenizer might be better to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treebank Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from string import punctuation\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"rev_text_lower\"] = reviews['reviewText'].apply(lambda rev: str(rev)\\\n",
    "                                                        .translate(str.maketrans('', '', punctuation))\\\n",
    "                                                        .replace(\"<br />\", \" \")\\\n",
    "                                                        .lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rev_text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Math has never been my strongest suit so I tho...</td>\n",
       "      <td>math has never been my strongest suit so i tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>works good</td>\n",
       "      <td>works good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  \\\n",
       "1746  Math has never been my strongest suit so I tho...   \n",
       "2552                                         works good   \n",
       "\n",
       "                                         rev_text_lower  \n",
       "1746  math has never been my strongest suit so i tho...  \n",
       "2552                                         works good  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[['reviewText','rev_text_lower']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"tb_tokens\"] = reviews['rev_text_lower'].apply(lambda rev: tb_tokenizer.tokenize(str(rev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rev_text_lower</th>\n",
       "      <th>tb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Weird tech glitches right out of the box. I ca...</td>\n",
       "      <td>weird tech glitches right out of the box i can...</td>\n",
       "      <td>[weird, tech, glitches, right, out, of, the, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Had weird sexual thing in the middle, graphic ...</td>\n",
       "      <td>had weird sexual thing in the middle graphic c...</td>\n",
       "      <td>[had, weird, sexual, thing, in, the, middle, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>Love it!! Best buy ever!! Great seller!!</td>\n",
       "      <td>love it best buy ever great seller</td>\n",
       "      <td>[love, it, best, buy, ever, great, seller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  \\\n",
       "405   Weird tech glitches right out of the box. I ca...   \n",
       "34    Had weird sexual thing in the middle, graphic ...   \n",
       "3449           Love it!! Best buy ever!! Great seller!!   \n",
       "\n",
       "                                         rev_text_lower  \\\n",
       "405   weird tech glitches right out of the box i can...   \n",
       "34    had weird sexual thing in the middle graphic c...   \n",
       "3449                 love it best buy ever great seller   \n",
       "\n",
       "                                              tb_tokens  \n",
       "405   [weird, tech, glitches, right, out, of, the, b...  \n",
       "34    [had, weird, sexual, thing, in, the, middle, g...  \n",
       "3449         [love, it, best, buy, ever, great, seller]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[['reviewText', 'rev_text_lower', 'tb_tokens']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casual Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import casual_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['casual_tokens'] = reviews['rev_text_lower'].apply(lambda rev: casual_tokenize(str(rev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>casual_tokens</th>\n",
       "      <th>tb_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>Decent price and quality.\\nFeels good in the h...</td>\n",
       "      <td>[decent, price, and, quality, feels, good, in,...</td>\n",
       "      <td>[decent, price, and, quality, feels, good, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>They have fixed everything wrong with the alre...</td>\n",
       "      <td>[they, have, fixed, everything, wrong, with, t...</td>\n",
       "      <td>[they, have, fixed, everything, wrong, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>Assassin's Creed is one of those series that i...</td>\n",
       "      <td>[assassins, creed, is, one, of, those, series,...</td>\n",
       "      <td>[assassins, creed, is, one, of, those, series,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  \\\n",
       "2348  Decent price and quality.\\nFeels good in the h...   \n",
       "4182  They have fixed everything wrong with the alre...   \n",
       "3463  Assassin's Creed is one of those series that i...   \n",
       "\n",
       "                                          casual_tokens  \\\n",
       "2348  [decent, price, and, quality, feels, good, in,...   \n",
       "4182  [they, have, fixed, everything, wrong, with, t...   \n",
       "3463  [assassins, creed, is, one, of, those, series,...   \n",
       "\n",
       "                                              tb_tokens  \n",
       "2348  [decent, price, and, quality, feels, good, in,...  \n",
       "4182  [they, have, fixed, everything, wrong, with, t...  \n",
       "3463  [assassins, creed, is, one, of, those, series,...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[['reviewText','casual_tokens','tb_tokens']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing StopWords\n",
    "This part has been remvoed as removing stop words is not good for sentiment analysis at all!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words.remove(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"not\" in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from string import punctuation\n",
    "#print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews['tokens_nosw'] = reviews['tb_tokens'].\\\n",
    "#    apply(lambda words: [w for w in words if w not in stop_words and w not in punctuation and w != \"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews[['tb_tokens','tokens_nosw']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['tokens_stemmed'] = reviews['tb_tokens'].apply(lambda words: [stemmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tb_tokens</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>[save, your, money, and, get, the, eforcity, o...</td>\n",
       "      <td>[save, your, money, and, get, the, eforc, one,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>[my, son, got, this, a, few, weeks, ago, and, ...</td>\n",
       "      <td>[my, son, got, thi, a, few, week, ago, and, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>[one, of, the, best, dragonball, z, games, yey...</td>\n",
       "      <td>[one, of, the, best, dragonbal, z, game, yey, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tb_tokens  \\\n",
       "1350  [save, your, money, and, get, the, eforcity, o...   \n",
       "3696  [my, son, got, this, a, few, weeks, ago, and, ...   \n",
       "3289  [one, of, the, best, dragonball, z, games, yey...   \n",
       "\n",
       "                                         tokens_stemmed  \n",
       "1350  [save, your, money, and, get, the, eforc, one,...  \n",
       "3696  [my, son, got, thi, a, few, week, ago, and, pa...  \n",
       "3289  [one, of, the, best, dragonbal, z, game, yey, ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[['tb_tokens','tokens_stemmed']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rickylam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/rickylam/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rickylam/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/rickylam/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SentiWordNetCorpusReader in '/Users/rickylam/nltk_data/corpora/sentiwordnet'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\"\n",
    "        Convert between the PennTreebank tags to simple Wordnet tags\n",
    "        PennTreebank tags:\n",
    "        https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "        simple Wordnet tags:\n",
    "        https://www.nltk.org/_modules/nltk/tag/mapping.html\n",
    "    \"\"\"\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def get_lemas(tokens):\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        pos = penn_to_wn(pos_tag([token])[0][1])\n",
    "        if pos:\n",
    "            lemma = lemmatizer.lemmatize(token, pos)\n",
    "            if lemma:\n",
    "                lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemas_breakdown(tokens):\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        print('=====')\n",
    "        print('>>>')\n",
    "        print(token)\n",
    "        print(pos_tag([token]))\n",
    "#         universal, wsj, brown\n",
    "        print(pos_tag([token])[0])\n",
    "        print(pos_tag([token])[0][1])\n",
    "        pos = penn_to_wn(pos_tag([token])[0][1])\n",
    "        if pos:\n",
    "            print('>>')\n",
    "            lemma = lemmatizer.lemmatize(token, pos)\n",
    "            print(lemma)\n",
    "            if lemma:\n",
    "                print('>')\n",
    "                lemmas.append(lemma)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'great',\n",
       " 'game',\n",
       " 'to',\n",
       " 'pass',\n",
       " 'time',\n",
       " 'and',\n",
       " 'have',\n",
       " 'tons',\n",
       " 'of',\n",
       " 'fun',\n",
       " 'doing',\n",
       " 'it',\n",
       " 'the',\n",
       " 'mini',\n",
       " 'games',\n",
       " 'are',\n",
       " 'alot',\n",
       " 'of',\n",
       " 'fun',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ds']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['tb_tokens'][4222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      ">>>\n",
      "a\n",
      "[('a', 'DT')]\n",
      "('a', 'DT')\n",
      "DT\n",
      "=====\n",
      ">>>\n",
      "great\n",
      "[('great', 'JJ')]\n",
      "('great', 'JJ')\n",
      "JJ\n",
      ">>\n",
      "great\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "game\n",
      "[('game', 'NN')]\n",
      "('game', 'NN')\n",
      "NN\n",
      ">>\n",
      "game\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "to\n",
      "[('to', 'TO')]\n",
      "('to', 'TO')\n",
      "TO\n",
      "=====\n",
      ">>>\n",
      "pass\n",
      "[('pass', 'NN')]\n",
      "('pass', 'NN')\n",
      "NN\n",
      ">>\n",
      "pas\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "time\n",
      "[('time', 'NN')]\n",
      "('time', 'NN')\n",
      "NN\n",
      ">>\n",
      "time\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "and\n",
      "[('and', 'CC')]\n",
      "('and', 'CC')\n",
      "CC\n",
      "=====\n",
      ">>>\n",
      "have\n",
      "[('have', 'VB')]\n",
      "('have', 'VB')\n",
      "VB\n",
      ">>\n",
      "have\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "tons\n",
      "[('tons', 'NNS')]\n",
      "('tons', 'NNS')\n",
      "NNS\n",
      ">>\n",
      "ton\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "of\n",
      "[('of', 'IN')]\n",
      "('of', 'IN')\n",
      "IN\n",
      "=====\n",
      ">>>\n",
      "fun\n",
      "[('fun', 'NN')]\n",
      "('fun', 'NN')\n",
      "NN\n",
      ">>\n",
      "fun\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "doing\n",
      "[('doing', 'VBG')]\n",
      "('doing', 'VBG')\n",
      "VBG\n",
      ">>\n",
      "do\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "it\n",
      "[('it', 'PRP')]\n",
      "('it', 'PRP')\n",
      "PRP\n",
      "=====\n",
      ">>>\n",
      "the\n",
      "[('the', 'DT')]\n",
      "('the', 'DT')\n",
      "DT\n",
      "=====\n",
      ">>>\n",
      "mini\n",
      "[('mini', 'NN')]\n",
      "('mini', 'NN')\n",
      "NN\n",
      ">>\n",
      "mini\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "games\n",
      "[('games', 'NNS')]\n",
      "('games', 'NNS')\n",
      "NNS\n",
      ">>\n",
      "game\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "are\n",
      "[('are', 'VBP')]\n",
      "('are', 'VBP')\n",
      "VBP\n",
      ">>\n",
      "be\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "alot\n",
      "[('alot', 'NN')]\n",
      "('alot', 'NN')\n",
      "NN\n",
      ">>\n",
      "alot\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "of\n",
      "[('of', 'IN')]\n",
      "('of', 'IN')\n",
      "IN\n",
      "=====\n",
      ">>>\n",
      "fun\n",
      "[('fun', 'NN')]\n",
      "('fun', 'NN')\n",
      "NN\n",
      ">>\n",
      "fun\n",
      ">\n",
      "=====\n",
      ">>>\n",
      "on\n",
      "[('on', 'IN')]\n",
      "('on', 'IN')\n",
      "IN\n",
      "=====\n",
      ">>>\n",
      "the\n",
      "[('the', 'DT')]\n",
      "('the', 'DT')\n",
      "DT\n",
      "=====\n",
      ">>>\n",
      "ds\n",
      "[('ds', 'NN')]\n",
      "('ds', 'NN')\n",
      "NN\n",
      ">>\n",
      "d\n",
      ">\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['great',\n",
       " 'game',\n",
       " 'pas',\n",
       " 'time',\n",
       " 'have',\n",
       " 'ton',\n",
       " 'fun',\n",
       " 'do',\n",
       " 'mini',\n",
       " 'game',\n",
       " 'be',\n",
       " 'alot',\n",
       " 'fun',\n",
       " 'd']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lemas_breakdown(reviews['tb_tokens'][4222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['lemmas'] = reviews['tb_tokens'].apply(lambda tokens: get_lemas(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>Though I use the controller at no more than 1 ...</td>\n",
       "      <td>[though, i, use, the, control, at, no, more, t...</td>\n",
       "      <td>[i, use, controller, more, meter, away, foot, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>Meh.....</td>\n",
       "      <td>[meh]</td>\n",
       "      <td>[meh]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  \\\n",
       "2102  Though I use the controller at no more than 1 ...   \n",
       "1929                                           Meh.....   \n",
       "\n",
       "                                         tokens_stemmed  \\\n",
       "2102  [though, i, use, the, control, at, no, more, t...   \n",
       "1929                                              [meh]   \n",
       "\n",
       "                                                 lemmas  \n",
       "2102  [i, use, controller, more, meter, away, foot, ...  \n",
       "1929                                              [meh]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[['reviewText','tokens_stemmed','lemmas']].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Predictor Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(tokens):\n",
    "    score = 0\n",
    "    tags = pos_tag(tokens)\n",
    "    for word, tag in tags:\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if not wn_tag:\n",
    "            continue\n",
    "        synsets = wn.synsets(word, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        \n",
    "        #most common set:\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        \n",
    "        score += (swn_synset.pos_score() - swn_synset.neg_score())\n",
    "        \n",
    "    return score\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test\n",
    "swn.senti_synset(wn.synsets(\"Mary\", wn.NOUN)[0].name()).neg_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the mother of Jesus; Christians refer to her as the Virgin Mary; she is especially honored by Roman Catholics'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"Mary\", wn.NOUN)[0].definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['sentiment_score'] = reviews['lemmas'].apply(lambda tokens: get_sentiment_score(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>Excellent game!!!!</td>\n",
       "      <td>[excellent, game]</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>I just do not understand why Amazon does not r...</td>\n",
       "      <td>[i, just, do, not, understand, amazon, do, not...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>I could go on and on about how much fun this g...</td>\n",
       "      <td>[i, go, much, fun, game, be, i, save, time, ju...</td>\n",
       "      <td>2.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2545</th>\n",
       "      <td>Never was a tomb raider fan but after playing ...</td>\n",
       "      <td>[never, be, tomb, raider, fan, play, i, say, g...</td>\n",
       "      <td>2.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>The review score of this game is one of the mo...</td>\n",
       "      <td>[review, score, game, be, most, eloquent, exam...</td>\n",
       "      <td>5.069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  \\\n",
       "3325                                 Excellent game!!!!   \n",
       "1303  I just do not understand why Amazon does not r...   \n",
       "3527  I could go on and on about how much fun this g...   \n",
       "2545  Never was a tomb raider fan but after playing ...   \n",
       "3371  The review score of this game is one of the mo...   \n",
       "\n",
       "                                                 lemmas  sentiment_score  \n",
       "3325                                  [excellent, game]            1.000  \n",
       "1303  [i, just, do, not, understand, amazon, do, not...            0.125  \n",
       "3527  [i, go, much, fun, game, be, i, save, time, ju...            2.500  \n",
       "2545  [never, be, tomb, raider, fan, play, i, say, g...            2.125  \n",
       "3371  [review, score, game, be, most, eloquent, exam...            5.069  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[['reviewText','lemmas','sentiment_score']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>awesome i love destroying stuff its fun to pla...</td>\n",
       "      <td>[awesome, i, love, destroy, stuff, fun, play, ...</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>Kinda difficult to install correctly (eg no bu...</td>\n",
       "      <td>[kinda, difficult, install, correctly, eg, bub...</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>good product but i feel this should've been in...</td>\n",
       "      <td>[good, product, i, feel, shouldve, be, include...</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>OK</td>\n",
       "      <td>[ok]</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>6 year old loves it</td>\n",
       "      <td>[year, old, love]</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  \\\n",
       "3788  awesome i love destroying stuff its fun to pla...   \n",
       "2371  Kinda difficult to install correctly (eg no bu...   \n",
       "2109  good product but i feel this should've been in...   \n",
       "1937                                                 OK   \n",
       "4276                                6 year old loves it   \n",
       "\n",
       "                                                 lemmas  sentiment_score  \n",
       "3788  [awesome, i, love, destroy, stuff, fun, play, ...            2.000  \n",
       "2371  [kinda, difficult, install, correctly, eg, bub...            0.125  \n",
       "2109  [good, product, i, feel, shouldve, be, include...            0.625  \n",
       "1937                                               [ok]            0.000  \n",
       "4276                                  [year, old, love]            1.000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[reviews['reviewText'].str.len()<=100][['reviewText','lemmas','sentiment_score']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
